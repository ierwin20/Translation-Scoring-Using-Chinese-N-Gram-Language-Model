{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bec2986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import re\n",
    "import nltk\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from nltk.util import everygrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tatoebatools import ParallelCorpus\n",
    "import random\n",
    "import pinyin\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3ef3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\r\\n<LCMC ver=\"pinyin\"><header><corpusDesc><corpusName>The Lancaster Corpus of Mandarin Chinese </corpusName><creator>Created by the Department of Linguistics, Lancaster University </creator><funding>Funded by the Economic and social Research Council (ESRC), UK </funding><designer>Designed by Anthony McEnery and Zhonghua Xiao </designer><supervision>Supervised by Anthony McEnery </supervision><textcollect>Texts collected by Zhonghua Xiao </textcollect><proofread>Electronic texts proofread and corrected by Zhonghua Xiao and Xin Huang </proofread><POStag>Segmented and POS-tagged by Zhonghua Xiao </POStag><PinyinConv>Converted into Pinyin by NJStar Chinese Word Processor for Windows Version 4.35</PinyinConv><unicodify>Converted into Unicode by Multilingual Corpus Tools (MLCT) developed by Scott Piao and Andrew Wilson </unicodify></corpusDesc><publication><publisher>Department of Linguistics, Lancaster University, LA1 4YT, UK </publisher><availability re'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The corpus comes as 15 xml files of different genre categories. This takes the zipped folder of files and adds the text of each to one string to be used as one corpus.\n",
    "corpus = b''\n",
    "with zipfile.ZipFile('pinyin.zip') as z:\n",
    "    for filename in z.namelist():\n",
    "        if not os.path.isdir(filename):\n",
    "            with z.open(filename) as f:\n",
    "                corpus += f.read()\n",
    "corpus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc7432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['da4 qiang2 nei4 wai4 bei3 jing1 shi4 jian1 yu4 ji4 shi2 san1',\n",
       " 'tian2 zhen1 ying3',\n",
       " 'huo4 xu3 yan2 tong2 yi3 zai4 zhe4 mang2 lu4 zhong1 kai1 shi3 suan4 qing1 le5 wei2 na3 jiu3 shi2 wan4 jin1 liang2 piao4 ta1 ying4 fu4 chu1 de5 ju4 da4 dai4 jia4',\n",
       " 'ta1 you4 cong2 zhe4 dai4 jia4 zhong1 xue2 xi2 zhao2 zai4 xue2 xiao4 zhong1 cong2 wei4 xue2 guo4 de5 zhi1 shi2 xue2 xi2 zhao2 ren2 sheng1',\n",
       " 'jiu4 xiao4 li4 ge4 ren2 er2 yan2 ta1 zou3 zhao2 yi1 tiao2 bei1 ju4 shi4 de5 lu4',\n",
       " 'ruo4 cong2 she4 hui4 de5 jiao3 du4 lai2 kan4 xiao4 li4 de5 pan4 xing2 shi4 jiao4 yu4 de5 shi1 bai4 jia1 ting2 de5 xue2 xiao4 de5',\n",
       " 'fu4 mu3 qi1 wang4 er2 zi5 cheng2 long2',\n",
       " 'zhong4 dian3 zhong1 xue2 xue2 sheng1 de5 gui4 guan4 shi3 ta1 yi1 men2 xin1 si1 ba3 zi4 ji3 de5 qian2 tu2 he2 qing1 hua2 bei3 da4 jin3 lian2 yi1 qi3 ta1 chou2 chu2 man3 zhi4 jue2 de5 sheng4 quan4 zai4 wo4',\n",
       " 'dan4 shi4 gao1 zhong1 bi4 ye4 ti3 jian3 biao3 shang4 de5 se4 mang2 er4 zi4 ba3 ta1 da3 de5 yun1 tou2 zhuan3 xiang4 ta1 bu4 de5 yi3 bao4 le5 shi1 fan4 yuan4 xiao4 jin4 guan3 lu4 qu3 ta1 de5 shi1 fan4 da4 xue2 yi1 ran2 shi4 quan2 guo2 zhong4 dian3 dan4 ta1 jue2 de5 zi4 ji3 yi3 cong2 bao3 ta3 ding3 shang4 die2 luo4 xia4 lai2 le5',\n",
       " 'ru4 xue2 hou4 xiao4 li4 cong2 bu4 pei4 dai4 xiao4 hui1 wei4 lai2 hai2 zi5 wang2 de5 qian2 tu2 shi3 ta1 zhong1 ri4 yan4 yan4 gan3 dao4 huo2 zhao2 wu2 wei4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a list of sentences as indicated in the corpus by the sentence tags\n",
    "xmlSentences = re.findall(b'<s n=\"\\d+\"> (.+) </s>', corpus)\n",
    "\n",
    "sentences = []\n",
    "for sentence in xmlSentences:\n",
    "    #remove punctuation and gaps\n",
    "    sentence = re.sub(b'<c POS=\"..?\">\\S+</c>|<gap>omission</gap>', b'', sentence)\n",
    "    #remove all other tags\n",
    "    sentence = re.sub(b'<w POS=\" ?..? ?\">|</. ?>|<s n=\"....\">', b'', sentence)\n",
    "    #remove other random characters\n",
    "    sentence = re.sub(b'>', b'', sentence)\n",
    "    #convert back to character string\n",
    "    sentence = sentence.decode()\n",
    "    #strip trailing whitespace\n",
    "    sentence = sentence.strip()\n",
    "    #spacing for syllables\n",
    "    sentence = \"\".join(sentence.split())\n",
    "    words = re.findall('.*?[\\d+]', sentence)\n",
    "    sentence = \" \".join(words)\n",
    "    \n",
    "    sentences.append(sentence)\n",
    "\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058b3a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['da4',\n",
       "  'qiang2',\n",
       "  'nei4',\n",
       "  'wai4',\n",
       "  'bei3',\n",
       "  'jing1',\n",
       "  'shi4',\n",
       "  'jian1',\n",
       "  'yu4',\n",
       "  'ji4',\n",
       "  'shi2',\n",
       "  'san1']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenize corpus\n",
    "tokenized_sentences = [sentence.split() for sentence in sentences]\n",
    "tokenized_sentences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a962d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train language model\n",
    "train, vocabulary = padded_everygram_pipeline(2, tokenized_sentences)\n",
    "lm = MLE(2)\n",
    "lm.fit(train, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a78f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #preprocess sample sentence\n",
    "# sentence = \"Wo3 you3dian3 kun4huo4\" #means: I'm a little confused\n",
    "# #all lowercase\n",
    "# sentence = sentence.lower().split()\n",
    "# #turn into ngram tuples\n",
    "# sentence = list(nltk.ngrams(sentence, 2))\n",
    "# sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9803365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get perplexity of sample sentence\n",
    "# perplexity = lm.perplexity(sentence)\n",
    "# perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586ff905",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cedict_ts.u8', encoding = 'utf-8') as file:\n",
    "    text = file.read()\n",
    "    lines = text.split('\\n')\n",
    "    dict_lines = list(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35de8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "        if line == '':\n",
    "            dict_lines.remove(line)\n",
    "            return 0\n",
    "        line = line.rstrip('/')\n",
    "        line = line.rstrip('/')\n",
    "        if len(line) <= 1:\n",
    "            return 0\n",
    "        p = line.split(']')[0]\n",
    "        e = line.split(']')[1]\n",
    "        e = re.sub(r'\\([^)]*\\)', '', e).split('(')[0]\n",
    "        e2 = e.strip().rstrip('/').lstrip('/').split('/')\n",
    "        english = [lemmatizer.lemmatize(word) for word in e2]\n",
    "        pinyin = p.split('[')[1]\n",
    "        \n",
    "        pinList.append(pinyin)\n",
    "        engList.append(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b38dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinList = []\n",
    "engList = []\n",
    "for line in dict_lines:\n",
    "    parse_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29cb2ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('san1 shi2 liu4 zi4 mu3',\n",
       "  ['thirty six initial consonants of Song phonetic theory']),\n",
       " ('san1 shi2 liu4 ji4',\n",
       "  ['The Thirty-Six Stratagems, a Chinese essay used to illustrate a series of stratagems used in politics, war, and in civil interaction',\n",
       "   'all the possible schemes and stratagems']),\n",
       " ('san1 shi2 liu4 ji4 , zou3 wei2 shang4 ce4',\n",
       "  ['of the thirty-six stratagems, the best option is to flee ',\n",
       "   'the best thing to do is leave']),\n",
       " ('san1 shi2 liu4 ji4 , zou3 wei2 shang4 ji4',\n",
       "  ['see 三十六計，走為上策|三十六计，走为上策[san1 shi2 liu4 ji4 , zou3 wei2 shang4 ce4']),\n",
       " ('san1 shi2 nian2 he2 dong1 , san1 shi2 nian2 he2 xi1',\n",
       "  ['the river flows thirty years to the East, thirty years to the West ',\n",
       "   'change is the only constant']),\n",
       " ('san1 shi2 er2 li4', ['thirty years old and therefore independent']),\n",
       " ('san1 qian1 da4 qian1 shi4 jie4', ['cosmos']),\n",
       " ('San1 yuan2', ['Sanyuan County in Xianyang 咸陽|咸阳[Xian2 yang2']),\n",
       " ('san1 yuan2 ze2', ['the Three Principles']),\n",
       " ('San1 yuan2 Xian4', ['Sanyuan County in Xianyang 咸陽|咸阳[Xian2 yang2']),\n",
       " ('san1 cha1 ji3', ['trident']),\n",
       " ('san1 cha1 shen2 jing1', ['trigeminal nerve']),\n",
       " ('san1 fan3', ['\"Three Anti\" campaign , early PRC purge of 1951-52']),\n",
       " ('san1 fan3 yun4 dong4',\n",
       "  ['\"Three Anti\" campaign , early PRC purge of 1951-52']),\n",
       " ('san1 ju4 hua4 bu4 li2 ben3 hang2', ['to talk shop all the time']),\n",
       " ('San1 tai2', ['Santai county in Mianyang 綿陽|绵阳[Mian2 yang2']),\n",
       " ('San1 tai2 xian4', ['Santai county in Mianyang 綿陽|绵阳[Mian2 yang2']),\n",
       " ('san1 he2 yi1', ['three in one', 'triple']),\n",
       " ('san1 he2 yi1 yi4 miao2', ['DTP vaccination']),\n",
       " ('san1 he2 tu3', ['mortar', 'concrete', 'cement']),\n",
       " ('san1 he2 xing1', ['triple star system']),\n",
       " ('san1 he2 hui4',\n",
       "  ['triad, Chinese crime gang',\n",
       "   'triad society, anti-Manchu secret society in Qing-dynasty China']),\n",
       " ('san1 he2 yuan4',\n",
       "  ['residence consisting of structures surrounding a courtyard on three sides']),\n",
       " ('san1 wei4 xian4', ['shamisen, three-stringed Japanese musical instrument']),\n",
       " ('san1 he2 xian2',\n",
       "  ['triad', 'musical chord of three notes, such as major triad do-mi-so']),\n",
       " ('San1 guo2',\n",
       "  ['Three Kingdoms period  in Chinese history',\n",
       "   'several Three Kingdoms periods in Korean history, esp. from 1st century AD to unification under Silla 新羅|新罗[Xin1 luo2']),\n",
       " ('San1 guo2 shi3 ji4',\n",
       "  ['History of Three Kingdoms , the oldest extant Korean history, compiled under Kim Busik 金富軾|金富轼[Jin1 Fu4 shi4']),\n",
       " ('San1 guo2 zhi4',\n",
       "  ['History of the Three Kingdoms, fourth of the 24 dynastic histories 二十四史[Er4 shi2 si4 Shi3']),\n",
       " ('San1 guo2 Yan3 yi4',\n",
       "  ['Romance of the Three Kingdoms by Luo Guanzhong 羅貫中|罗贯中[Luo2 Guan4 zhong1']),\n",
       " ('san1 wei2',\n",
       "  [\"BWH, abbr. for a woman's three measurements, namely: bust 胸圍|胸围[xiong1 wei2\"]),\n",
       " ('San1 di4 men2',\n",
       "  ['Santimen township in Pingtung County 屏東縣|屏东县[Ping2 dong1 Xian4']),\n",
       " ('San1 di4 men2 xiang1',\n",
       "  ['Santimen township in Pingtung County 屏東縣|屏东县[Ping2 dong1 Xian4']),\n",
       " ('San1 Da4 Ji4 lu:4 Ba1 Xiang4 Zhu4 yi4',\n",
       "  ['the Three Rules of Discipline and Eight Points for Attention, a military doctrine issued in 1928 by Mao Zedong for the Red Army, which included a number of injunctions demanding high standards of behavior and respect for civilians during wartime']),\n",
       " ('san1 tian1 bu4 da3 , shang4 fang2 jie1 wa3',\n",
       "  ['three days without a beating, and a child will scale the roof to rip the tiles ',\n",
       "   'spare the rod, spoil the child']),\n",
       " ('san1 tian1 liang3 tou2',\n",
       "  ['lit. twice every three days ; practically every day', 'frequently']),\n",
       " ('san1 tian1 da3 yu2 , liang3 tian1 shai4 wang3',\n",
       "  ['lit. to fish for three days and sun-dry the nets for two days ',\n",
       "   'fig. not to persevere in doing sth',\n",
       "   'to do sth by fits and starts']),\n",
       " ('san1 yi2 jiao4', ['the three foreign religions']),\n",
       " ('san1 gu1 liu4 po2', ['women with disreputable or illegal professions']),\n",
       " ('San1 zi4 Jing1',\n",
       "  ['Three Character Classic, 13th century reading primer consisting of Confucian tenets in lines of 3 characters']),\n",
       " ('san1 zi4 jing1', [' swearword', 'four-letter word']),\n",
       " ('san1 guan1 da4 di4',\n",
       "  ['the three gods in charge of heaven, earth and water']),\n",
       " ('San1 jia1 cun1',\n",
       "  ['lit. village of three households',\n",
       "   'name of essay column in Beijing newspaper from 1961-1966, written by Deng Tuo 鄧拓|邓拓, Wu Han 吳晗|吴晗 and Liao Mosha 廖沫沙, criticized as anti-party during the Cultural Revolution']),\n",
       " ('san1 bao3',\n",
       "  ['the Three Precious Treasures of Buddhism, namely: the Buddha 佛, the Dharma 法 , and the Sangha 僧']),\n",
       " ('San1 bao3 tai4 jian4',\n",
       "  ['Sanbao Eunuch, official title of Zheng He 鄭和|郑和[Zheng4 He2']),\n",
       " ('san1 bao3 niao3', [' oriental dollarbird']),\n",
       " ('san1 cun4 bu4 lan4 zhi1 she2',\n",
       "  ['to have a silver tongue', 'to have the gift of the gab']),\n",
       " ('san1 dui4 san1 dou4 niu2', ['three-on-three basketball game']),\n",
       " ('san1 xiao3', ['  what the hell?']),\n",
       " ('san1 jian1 shan1 zhi3 jian3', ['harringtonine']),\n",
       " ('san1 ti4 zhuo1', ['three-drawer desk']),\n",
       " ('San1 shan1', ['Sanshan district of Wuhu city 蕪湖市|芜湖市[Wu2 hu2 shi4']),\n",
       " ('San1 shan1 qu1', ['Sanshan district of Wuhu city 蕪湖市|芜湖市[Wu2 hu2 shi4']),\n",
       " ('San1 cha4 kou3',\n",
       "  ['At the Crossroads, famous opera, based on a story from 水滸傳|水浒传[Shui3 hu3 Zhuan4']),\n",
       " ('San1 dao3 You2 ji4 fu1', ['Mishima Yukio , Japanese author, pen name of']),\n",
       " ('San1 xia2',\n",
       "  ['Three Gorges on the Chang Jiang or Yangtze, namely: Qutang Gorge 瞿塘峽|瞿塘峡[Qu2 tang2 Xia2']),\n",
       " ('San1 xia2 Da4 ba4', ['Three Gorges Dam on the Yangtze River']),\n",
       " ('San1 xia2 Shui3 ku4',\n",
       "  ['Three Gorges Reservoir on the Changjiang or Yangtze']),\n",
       " ('San1 xia2 zhen4',\n",
       "  ['Sanxia or Sanhsia town in New Taipei City 新北市[Xin1 bei3 shi4']),\n",
       " ('san1 du4', ['third']),\n",
       " ('san1 xiang1', ['sedan']),\n",
       " ('san1 fei4',\n",
       "  ['three types of waste product, namely: waste water 廢水|废水[fei4 shui3']),\n",
       " ('san1 xian2',\n",
       "  ['sanxian, large family of 3-stringed plucked musical instruments, with snakeskin covered wooden soundbox and long neck, used in folk music, opera and Chinese orchestra']),\n",
       " ('San1 de2 li4', ['Suntory, Japanese beverage company']),\n",
       " ('san1 cong2 si4 de2',\n",
       "  ['Confucian moral injunctions for women, namely: obey in turn three men father, husband and son, plus the four virtues of morality 德[de2']),\n",
       " ('san1 xin1 er4 yi4',\n",
       "  ['in two minds about sth ', 'half-hearted', 'shilly-shallying']),\n",
       " ('san1 si1 er2 hou4 xing2',\n",
       "  ['think again and again before acting ; consider carefully in advance']),\n",
       " ('san1 si1 er2 xing2',\n",
       "  [\"think three times then go ; don't act before you've thought it through carefully\"]),\n",
       " ('san1 shou3 bing4', ['repetitive strain injury']),\n",
       " ('san1 ao4 tang1', [\"san'ao decoction\"]),\n",
       " ('san1 zhen4',\n",
       "  ['to strike out',\n",
       "   'strikeout ',\n",
       "   ' to ditch',\n",
       "   'to eliminate from consideration']),\n",
       " ('san1 zhen4 chu1 ju2', ['see 三振[san1 zhen4']),\n",
       " ('San1 Jiao4', ['the Three Doctrines']),\n",
       " ('san1 jiao4 jiu3 liu2',\n",
       "  ['the Three Religions  and Nine Schools ', 'fig. people from all trades']),\n",
       " ('san1 wen2 zhi4', ['sandwich']),\n",
       " ('san1 wen2 yu2', ['salmon']),\n",
       " ('san1 zu2', [' three generations ', 'three clans']),\n",
       " ('san1 xun2 jiu3 shi2',\n",
       "  ['lit. to have only nine meals in thirty days ',\n",
       "   'fig.  on the brink of starvation',\n",
       "   'in dire straits']),\n",
       " ('San1 ming2', ['Sanming, prefecture-level city in Fujian']),\n",
       " ('San1 ming2 shi4', ['Sanming, prefecture-level city in Fujian']),\n",
       " ('san1 ming2 zhi4', ['sandwich ', 'CL:個|个[ge4']),\n",
       " ('San1 xing1',\n",
       "  ['Sanxing or Sanhsing Township in Yilan County 宜蘭縣|宜兰县[Yi2 lan2 Xian4']),\n",
       " ('san1 xing1', ['three major stars of the Three Stars 參宿|参宿[Shen1 xiu4']),\n",
       " ('San1 xing1 dui1',\n",
       "  ['archaeological site of Sanxingdui outside Chengdu , exhibiting remarkable bronze artifacts from the 11-12th centuries BC']),\n",
       " ('San1 xing1 Xiang1',\n",
       "  ['Sanxing or Sanhsing Township in Yilan County 宜蘭縣|宜兰县[Yi2 lan2 Xian4']),\n",
       " ('San1 xing1 Ji2 tuan2', ['Samsung Group']),\n",
       " ('san1 chun1', ['the three spring months']),\n",
       " ('san1 mei4', ['Samadhi']),\n",
       " ('san1 geng1',\n",
       "  ['third of the five night watch periods 23:00-01:00 ',\n",
       "   'midnight',\n",
       "   'also pr. [san1 jin1']),\n",
       " ('san1 geng1 ban4 ye4', ['in the depth of the night', 'very late at night']),\n",
       " ('San1 Cao2',\n",
       "  ['the Three Caos , who established the Wei or Cao Wei dynasty 曹魏, and were all three noted poets and calligraphers']),\n",
       " ('San1 yue4', ['March', 'third month']),\n",
       " ('san1 yue4 fen4', ['March']),\n",
       " ('San1 yue4 Jie1',\n",
       "  ['Third Month Fair, traditional festival of the Bai Nationality 白族[Bai2 zu2']),\n",
       " ('san1 peng2 si4 you3', ['friend', 'crony']),\n",
       " ('san1 ban3', ['sampan']),\n",
       " ('san1 zhu4 men2', ['  wicket']),\n",
       " ('san1 kuang4 lan2', ['radical 匚[fang1']),\n",
       " ('san1 tiao2', ['three of a kind']),\n",
       " ('san1 ji2 guan3', ['triode']),\n",
       " ('san1 quan2 fen1 li4', ['separation of powers'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = list(zip(pinList, engList))\n",
    "z[1200:1300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0391e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #grade word order\n",
    "#     #all lowercase\n",
    "#     chi = chi.lower()\n",
    "#     #add sentence boundaries\n",
    "#     #test = \"</s> {} </s>\".format(test)\n",
    "#     #split into list of words\n",
    "#     chi = chi.split()\n",
    "#     #turn into ngram tuples\n",
    "#     chi = list(nltk.ngrams(chi, n))\n",
    "    \n",
    "#     print(f\"perplexity = {lm.entropy(chi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133171b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1516c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, translation in ParallelCorpus(\"cmn\", \"eng\"):\n",
    "        #characters to pinyin\n",
    "        p = pinyin.get(sentence.text, format = 'numerical')\n",
    "        pinyinString = \" \".join(re.findall('.*?[\\d+]', p))\n",
    "        #chinese english pairs\n",
    "        pairs.append((pinyinString, translation.text))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b606ab85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wo3 wan2 quan2 bu4 ren4 shi4 na4 ge4 nv3 ren2',\n",
       " \"I absolutely don't know that woman.\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a47b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', 'wo3')\n",
      "1717\n",
      "\n",
      "('wo3', 'wan2')\n",
      "10\n",
      "\n",
      "('wan2', 'quan2')\n",
      "283\n",
      "\n",
      "('quan2', 'bu4')\n",
      "216\n",
      "\n",
      "('bu4', 'ren4')\n",
      "39\n",
      "\n",
      "('ren4', 'shi4')\n",
      "17\n",
      "\n",
      "('shi4', 'na4')\n",
      "1\n",
      "\n",
      "('na4', 'ge4')\n",
      "3\n",
      "\n",
      "('ge4', 'nv3')\n",
      "0\n",
      "\n",
      "('nv3', 'ren2')\n",
      "0\n",
      "\n",
      "('ren2', '</s>')\n",
      "544\n",
      "\n",
      "283.0\n"
     ]
    }
   ],
   "source": [
    "s = pair[0]\n",
    "#s = 'jin1 nian2 wu3 yue4'\n",
    "\n",
    "#remove punctuation\n",
    "s = re.sub('\\W', \"\", s)\n",
    "words = re.findall('.*?[\\d+]', s)\n",
    "s = \" \".join(words)\n",
    "\n",
    "total = 0\n",
    "everygram = list(list(padded_everygram_pipeline(2, [s.split()])[0])[0])\n",
    "for gram in everygram:\n",
    "    if len(gram) == 1:\n",
    "        pass\n",
    "#         print(gram[0])\n",
    "#         print(lm.counts[gram[0]])\n",
    "#         print()\n",
    "    else:\n",
    "        print(gram)\n",
    "        print(lm.counts[[gram[0]]][gram[1]])\n",
    "        print()\n",
    "        total += lm.counts[[gram[0]]][gram[1]]\n",
    "        average = total/len(s.split())\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e51a712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(eng, chi):\n",
    "    #grade content words\n",
    "    translation = nltk.word_tokenize(chi)\n",
    "    english = eng.lower()\n",
    "    english = nltk.word_tokenize(english)\n",
    "\n",
    "    lemmaTranslation = [lemmatizer.lemmatize(lemmatizer.lemmatize(word, pos = 'v'), pos = 'n') for word in english]\n",
    "    \n",
    "    for i in range(len(pinList)):\n",
    "        if pinList[i] == 'wan2 quan2':\n",
    "            print(engList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d278d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['complete', 'whole', 'totally', 'entirely']\n"
     ]
    }
   ],
   "source": [
    "grade(pair[1], 'wo3 wan2 quan2 bu4 ren4 shi4 na4 ge4 nv3 ren2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
